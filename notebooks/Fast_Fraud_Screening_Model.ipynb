{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5581249-e59e-458b-a0b2-19520deecdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import (\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,ConfusionMatrixDisplay\n",
    ")\n",
    "import os\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d824f7b-85a6-4c70-94ea-4e6261858390",
   "metadata": {},
   "source": [
    "                                                       Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806ad42-a398-4da7-a177-5e43711d9703",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.read_csv('fraud_payment_data', sep=',', header=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc5d00-7104-44dd-b848-d8219cef3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing redudant columns\n",
    "total_data=total_data.drop('Time_step',axis=1)\n",
    "total_data=total_data.drop('Sender_lob',axis=1)\n",
    "total_data=total_data.drop('Sender_Id',axis=1)\n",
    "total_data=total_data.drop('Bene_Id',axis=1)\n",
    "total_data=total_data.drop('Transaction_Id',axis=1)\n",
    "\n",
    "#Apparently some transactions amounted to zero dollars. None of them were fraudulent, so I've removed them.\n",
    "total_data=total_data[total_data.USD_amount>0]\n",
    "#The NaNs represent self-transactions. Correct for these here.\n",
    "total_data['Sender_Country']=total_data['Sender_Country'].fillna(total_data['Bene_Country'])\n",
    "total_data['Bene_Country']=total_data['Bene_Country'].fillna(total_data['Sender_Country'])\n",
    "total_data['Sender_Sector'] = total_data['Sender_Sector'].fillna(-1)\n",
    "total_data['Sender_Account']=total_data['Sender_Account'].fillna(total_data['Bene_Account'])\n",
    "total_data['Bene_Account']=total_data['Bene_Account'].fillna(total_data['Sender_Account'])\n",
    "\n",
    "total_data=total_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1654d9f-ace5-4300-be94-000339a3cda9",
   "metadata": {},
   "source": [
    "                                                      Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97078308-4d40-4ca0-8b07-65315be56c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encode Transaction Type\n",
    "Type_feature= pd.get_dummies(total_data['Transaction_Type'], drop_first=True).astype(int)\n",
    "countries=list(set(total_data['Sender_Country']).union(set(total_data['Bene_Country'])))\n",
    "sectors=list(set(total_data['Sender_Sector']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4fc609-813f-4b80-ac6d-629ed0bb2c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to model the probability distribution of amount spent/recieved in a transaction given a historical average.\n",
    "#Returns probability of the transaction amount being greater than or equal to the one observed\n",
    "from scipy.stats import expon\n",
    "def amount_prob(mean,amount):\n",
    "  return expon.cdf(x=amount, scale=mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ab865-5e31-4789-8ba9-7c02edbfd3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that takes as input a node (an account), and a graph of transactions, and outputs the smallest  \n",
    "## number of transactions seperating the account from an account that had previously been involved in fraud. \n",
    "## The number of transactions is counted in the forward direction (outgoing transactions), and been restricted to at maximum length 5.\n",
    "## If greater than 5, then just return a huge value so the corresponding feature has a negligent value.\n",
    "def min_path_to_fraud(sender_node,G):\n",
    "    reach=nx.single_source_shortest_path_length(G, sender_node, cutoff=5)\n",
    "    Fraud_nodes=[node for node in reach.keys() if G.nodes[node]['Fraud_count']>0]\n",
    "    shortest_lengths = [reach[node] for node in Fraud_nodes]\n",
    "    if shortest_lengths:\n",
    "        return min(shortest_lengths)\n",
    "    else:\n",
    "        return 100000000 \n",
    "\n",
    "## An alternative measure of connectedness to the above. This measures what percentage of the nodes within 5\n",
    "## transactions of the given node are historically involved in fraud.\n",
    "def fraud_centrality(node,G):\n",
    "    reach=nx.single_source_shortest_path_length(G, node, cutoff=5).keys()\n",
    "    return len([node for node in reach if G.nodes[node]['Fraud_count']>0])/len(reach)\n",
    "\n",
    "##Returns whether a pair of sender, beneficiary has had a fraudulent transaction before\n",
    "def repeat_fraud(G,sender_node,bene_node):\n",
    "    Fraud= False\n",
    "    for transaction in G[sender_node][bene_node]:\n",
    "        if G[sender_node][bene_node][transaction]['Label']==1:\n",
    "            Fraud=True\n",
    "    return Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79dd690-ec70-41fd-b5ba-6b514d6bf536",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Initiate graph\n",
    "G = nx.MultiDiGraph()\n",
    "##Define dictionaries to keep track of fraud rates by country and sector\n",
    "country_dict=dict.fromkeys(countries, [0,0])\n",
    "sector_dict=dict.fromkeys(sectors, [0,0])\n",
    "\n",
    "##Initiate features we aim to engineer\n",
    "##bene/sender_prob is the probability explained above, Fraud_percentage_bene/sender is the percentage of fraudulent transactions among all \n",
    "##transactions (ingoing and outgoing) the sender account has been involved in, and Fraud_index_bene/sender is the distance given by the \n",
    "##min_path function above. Fraud centrality is given by the above function.  \n",
    "features_bene= pd.DataFrame(columns=['bene_prob','Fraud_percentage_bene','Fraud_index_bene',\n",
    "                                   'Fraud_centrality_bene','bene_in_deg','bene_out_deg','fraud_rate_by_country_bene'])\n",
    "features_sender= pd.DataFrame(columns=['sender_prob','Fraud_percentage_sender','Fraud_index_sender',\n",
    "                                    'Fraud_centrality_sender','sender_in_deg','sender_out_deg','fraud_rate_by_country_sender'])\n",
    "\n",
    "##Repeat fraud is given by the function above.\n",
    "features_general=pd.DataFrame(columns=['Repeat_Fraud','fraud_rate_by_sector'])\n",
    "for index, row in total_data.iterrows():\n",
    "    if index%1000==0:\n",
    "       print(index)\n",
    "    if index%10000==0:\n",
    "       total=pd.concat([features_bene,features_sender,features_general],axis=1)\n",
    "       total.to_csv('total_features', index=False)\n",
    "       print('Progress Saved!')\n",
    "        \n",
    "    ##First build general features\n",
    "    fraud_rate_by_country_sender=country_dict[row['Sender_Country']][0]\n",
    "    fraud_rate_by_country_Bene=country_dict[row['Bene_Country']][0]\n",
    "    fraud_rate_by_sector=sector_dict[row['Sender_Sector']][0]\n",
    "\n",
    "    country_dict[row['Sender_Country']][0]=(country_dict[row['Sender_Country']][0]*country_dict[row['Sender_Country']][1]+row['Label'])/(country_dict[row['Sender_Country']][1]+1)\n",
    "    country_dict[row['Sender_Country']][1]+=1\n",
    "    country_dict[row['Bene_Country']][0]=(country_dict[row['Bene_Country']][0]*country_dict[row['Bene_Country']][1]+row['Label'])/(country_dict[row['Bene_Country']][1]+1)\n",
    "    country_dict[row['Bene_Country']][1]+=1\n",
    "    sector_dict[row['Sender_Sector']][0]=(sector_dict[row['Sender_Sector']][0]*sector_dict[row['Sender_Sector']][1]+row['Label'])/(sector_dict[row['Sender_Sector']][1]+1)\n",
    "    sector_dict[row['Sender_Sector']][1]+=1\n",
    "    \n",
    "    new= not(G.has_edge(row['Sender_Account'],row['Bene_Account']))\n",
    "    repeatfraud=(not new) and repeat_fraud(G,row['Sender_Account'],row['Bene_Account'])\n",
    "    features_general.loc[index]=[repeatfraud,fraud_rate_by_sector]\n",
    "    \n",
    "    ##Build features related to sender accounts \n",
    "    check1=G.has_node(row['Sender_Account'])\n",
    "    if check1: ## If node already exists (i.e sender account involved in some transaction before)  \n",
    "      sender_in_deg=G.in_degree(row['Sender_Account'])\n",
    "      sender_out_deg=G.out_degree(row['Sender_Account'])\n",
    "      Fraud_percentage_sender=G.nodes[row['Sender_Account']]['Fraud_count']/(sender_in_deg+sender_out_deg)                                                                               \n",
    "      Fraud_centrality_sender=fraud_centrality(row['Sender_Account'],G)\n",
    "      Fraud_index_sender=1/(1+min_path_to_fraud(row['Sender_Account'],G))\n",
    "      if sender_out_deg>0: ## If node has been involved in an outgoing transaction\n",
    "        ##Engineer sender account features \n",
    "        sender_prob=amount_prob(G.nodes[row['Sender_Account']]['total_out']/sender_out_deg,row['USD_amount'])\n",
    "        features_sender.loc[index]=[sender_prob,Fraud_percentage_sender,Fraud_index_sender,\n",
    "                                    Fraud_centrality_sender,sender_in_deg,sender_out_deg,fraud_rate_by_country_sender]\n",
    "      else:\n",
    "        ##Engineer sender account features with default value for the prob feature as zero if no outgoing transaction history.\n",
    "        features_sender.loc[index]=[0,Fraud_percentage_sender,Fraud_index_sender,\n",
    "                                    Fraud_centrality_sender,sender_in_deg,0,fraud_rate_by_country_sender]\n",
    "        \n",
    "    else:##If node does not exist, put 0 as default value for features where appropriate \n",
    "      features_sender.loc[index]=[0,0,0,0,0,0,fraud_rate_by_country_sender]\n",
    "    \n",
    "    ##Repeat the same for beneficiary account\n",
    "    check2=G.has_node(row['Bene_Account'])\n",
    "    if check2:\n",
    "      Bene_in_deg=G.in_degree(row['Bene_Account'])\n",
    "      Bene_out_deg=G.out_degree(row['Bene_Account'])\n",
    "      Fraud_percentage_Bene=G.nodes[row['Bene_Account']]['Fraud_count']/(Bene_in_deg+Bene_out_deg)                                                                                 \n",
    "      Fraud_centrality_Bene=fraud_centrality(row['Bene_Account'],G)\n",
    "      Fraud_index_Bene=1/(1+min_path_to_fraud(row['Bene_Account'],G))\n",
    "      if Bene_in_deg>0: \n",
    "        Bene_prob=amount_prob(G.nodes[row['Bene_Account']]['total_in']/Bene_in_deg,row['USD_amount'])\n",
    "        features_bene.loc[index]=[Bene_prob,Fraud_percentage_Bene,Fraud_index_Bene,\n",
    "                                    Fraud_centrality_Bene,Bene_in_deg,Bene_out_deg,fraud_rate_by_country_Bene]\n",
    "      else:\n",
    "        features_bene.loc[index]=[0,Fraud_percentage_Bene,Fraud_index_Bene,\n",
    "                                    Fraud_centrality_Bene,0,Bene_out_deg,fraud_rate_by_country_Bene]\n",
    "    else:\n",
    "      features_bene.loc[index]=[0,0,0,0,0,0,fraud_rate_by_country_Bene]\n",
    "\n",
    "    check3=(row['Sender_Account']==row['Bene_Account'])#For self-transactions\n",
    "    ##Add/update edges and nodes in the graph corresponding to the transaction\n",
    "    if check1:  \n",
    "      G.nodes[row['Sender_Account']]['total_out']+=row['USD_amount']\n",
    "      G.nodes[row['Sender_Account']]['Fraud_count']+=row['Label']\n",
    "    else:\n",
    "      G.add_node(row['Sender_Account'], total_out=row['USD_amount'], total_in=0, Fraud_count=row['Label'])\n",
    "    if check2 or check3:  \n",
    "      G.nodes[row['Bene_Account']]['total_in']+=row['USD_amount']\n",
    "      G.nodes[row['Bene_Account']]['Fraud_count']+=row['Label']\n",
    "    else:\n",
    "      G.add_node(row['Bene_Account'], total_in=row['USD_amount'], total_out=0, Fraud_count=row['Label'])\n",
    "    \n",
    "    G.add_edge(row['Sender_Account'], row['Bene_Account'],Label=row['Label'])\n",
    "\n",
    "total=pd.concat([features_bene,features_sender,features_general,Type_feature],axis=1)\n",
    "total.to_csv('total_features', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df6a69f-1434-40df-8f42-6232abf4e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features=pd.read_csv('total_features', sep=',', header=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb72d0-0af1-44cc-ab76-af9c7a3c1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fed0f8-7c17-4a91-b066-392fa5cc3f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train, test, split \n",
    "train_features = final_features[0:1000000]\n",
    "val_features = final_features[1000000:1250000]\n",
    "test_features = final_features[1250000:-1]\n",
    "\n",
    "y_train = total_data['Label'][0:1000000]\n",
    "y_val   = total_data['Label'][1000000:1250000]\n",
    "y_test  = total_data['Label'][1250000:-1]\n",
    "\n",
    "#Fit scaler on TRAIN ONLY - this learns mean and std from training set \n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_features)\n",
    "\n",
    "# Transform val/test using the SAME scaler\n",
    "X_val  = scaler.transform(val_features)\n",
    "X_test = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a930d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aligning by index\n",
    "total_data = total_data.loc[final_features.index]\n",
    "\n",
    "#Make sure X and y are aligned\n",
    "X = pd.DataFrame(final_features)\n",
    "y = pd.Series(total_data[\"Label\"])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175939f-7653-4a28-9c28-2b51114e7e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Looking at the correlation matrix for our features in our training data\n",
    "corr_matrix = pd.concat([train_features,total_data[:1000000]['Label']],axis=1).corr()\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3c432b",
   "metadata": {},
   "source": [
    "                                                                Hyperparameter Tunning \n",
    "                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b8aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.05],\n",
    "    \"max_depth\": [6, 8],\n",
    "    \"n_estimators\": [400, 600],\n",
    "    \"min_child_weight\": [1, 2],\n",
    "    \"subsample\": [0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"gamma\": [0, 0.1\n",
    "    #pos weight tunned seperately\n",
    "]     \n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b2f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lift scorer\n",
    "#Lift scorer at top 10% because it reflects operational reality (limited review capacity), and shows model's ability to prioritize\n",
    "#Highest lift should be at top percentiles\n",
    "#Lift@10% = \"How good is my priority queue?\"\n",
    "def lift_scorer(estimator, X, y, top_pct=0.1):\n",
    "    y_true = y.to_numpy() \n",
    "    y_pred = estimator.predict_proba(X)[:, 1]\n",
    "    n = int(len(y_true) * top_pct)\n",
    "    idx = y_pred.argsort()[-n:]\n",
    "    return y_true[idx].sum() / (y_true.sum() * top_pct)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd62a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time Series Split \n",
    "tscv = TimeSeriesSplit(n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2e304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model with class imbalance\n",
    "xgb_base = XGBClassifier(scale_pos_weight=49, random_state=831)\n",
    "\n",
    "#Grid search\n",
    "xgb_search = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring=lift_scorer,\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "xgb_search.fit(X_train, y_train)\n",
    "print(f\"Best params: {xgb_search.best_params_}\")\n",
    "\n",
    "os.system('say \"First grid search finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d829c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(y_train)\n",
    "neg = counter[0]\n",
    "pos = counter[1]\n",
    "\n",
    "#Scale gives us our imbalance\n",
    "scale = neg / pos\n",
    "\n",
    "#lift scorer \n",
    "def lift_scorer(estimator, X, y, top_pct=0.1):\n",
    "    y_true = y.to_numpy() \n",
    "    y_pred = estimator.predict_proba(X)[:, 1]\n",
    "    n = int(len(y_true) * top_pct)\n",
    "    idx = y_pred.argsort()[-n:]\n",
    "    return y_true[idx].sum() / (y_true.sum() * top_pct)\n",
    "\n",
    "\n",
    "pos_weights = [scale * f for f in [0.5, 1, 2, 5, 7, 9, 11]]\n",
    "\n",
    "param_grid = {\n",
    "    \"scale_pos_weight\": pos_weights\n",
    "}\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "  colsample_bytree=0.8, \n",
    "  gamma=0.1, \n",
    "  learning_rate=0.01, \n",
    "  max_depth=8,\n",
    "  min_child_weight=2,\n",
    "  n_estimators= 600, \n",
    "  subsample= 0.9\n",
    ")\n",
    "\n",
    "search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring=lift_scorer,\n",
    "    cv=tscv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(search.best_params_)\n",
    "best_pos_weight = search.best_params_['scale_pos_weight_lift']\n",
    "\n",
    "import os\n",
    "os.system('say \"Pos weight grid search finished running\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a63460",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = LogisticRegression(C=1.0, max_iter=1000, random_state=831 )\n",
    "\n",
    "param_grid = {'class_weight': [{0: 1, 1: w} for w in [25, 49, 75, 100]]}\n",
    "\n",
    "search = GridSearchCV(lr, param_grid, scoring=lift_scorer, cv=tscv, n_jobs=-1 )\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f024a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = search.best_estimator_\n",
    "print(\"Best LR params:\", search.best_params_)\n",
    "print(\"Best CV lift:\", search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9551478d",
   "metadata": {},
   "source": [
    "                                                       Training Set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526b1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR training set \n",
    "y_pred_train_lr = best_lr.predict(X_train)\n",
    "y_pred_proba_train_lr = best_lr.predict_proba(X_train)[:, 1]\n",
    "lift_train_lr = lift_scorer(best_lr, X_train, y_train, top_pct=0.1)\n",
    "\n",
    "print(\"Logistic Regression - TRAINING\")\n",
    "print(f\"Lift@10%: {lift_train_lr:.2f}x\")\n",
    "print(classification_report(y_train, y_pred_train_lr))\n",
    "print(confusion_matrix(y_train, y_pred_train_lr))\n",
    "\n",
    "#LR validation set\n",
    "print(\"Logistic Regression - VALIDATION\")\n",
    "y_pred_val_lr = best_lr.predict(X_val)\n",
    "y_pred_proba_val_lr = best_lr.predict_proba(X_val)[:, 1]\n",
    "lift_val_lr = lift_scorer(best_lr, X_val, y_val, top_pct=0.1)\n",
    "print(f\"Lift@10%: {lift_val_lr:.2f}x\")\n",
    "print(classification_report(y_val, y_pred_val_lr))\n",
    "print(confusion_matrix(y_val, y_pred_val_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384d6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final XGB model\n",
    "val_model = XGBClassifier(\n",
    "    colsample_bytree=0.8, \n",
    "    gamma=0.1, \n",
    "    learning_rate=0.01, \n",
    "    min_child_weight=2,\n",
    "    n_estimators=600, \n",
    "    subsample=0.9,\n",
    "    scale_pos_weight=23,\n",
    "    max_depth=8,\n",
    "    random_state=831\n",
    ")\n",
    "val_model.fit(X_train, y_train)\n",
    "\n",
    "#XGB TRAINING SET \n",
    "y_pred_train = val_model.predict(X_train)\n",
    "y_pred_proba_train = val_model.predict_proba(X_train)[:, 1]\n",
    "lift_train = lift_scorer(val_model, X_train, y_train, top_pct=0.1)\n",
    "\n",
    "print(\"XGB - TRAINING\")\n",
    "print(f\"Lift@10%: {lift_train:.2f}x\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "\n",
    "#XGB VALIDATION SET \n",
    "print(\"\\n XGB - VALIDATION\")\n",
    "y_pred_val = val_model.predict(X_val)\n",
    "lift_val = lift_scorer(val_model, X_val, y_val, top_pct=0.1)\n",
    "print(f\"Lift@10%: {lift_val:.2f}x\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(confusion_matrix(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd6612",
   "metadata": {},
   "source": [
    "                                                       Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f28fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create DataFrame from test_features to extract column names\n",
    "df_temp = pd.DataFrame(test_features)\n",
    "feature_names = train_features.columns.tolist()  \n",
    "\n",
    "#combine training + validation\n",
    "X_final = np.vstack([X_train, X_val])\n",
    "y_final = np.concatenate([y_train, y_val])\n",
    "\n",
    "#final optimized XGB\n",
    "final_model = XGBClassifier(\n",
    "    colsample_bytree=0.8, \n",
    "  gamma=0.1, \n",
    "  learning_rate=0.01, \n",
    "  max_depth=8,\n",
    "  min_child_weight=2,\n",
    "  n_estimators= 600, \n",
    "  subsample= 0.9,\n",
    "  scale_pos_weight=23,\n",
    "  random_state=831\n",
    ")\n",
    "\n",
    "final_model.fit(X_final, y_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b033306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGB Test Set\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "y_pred_proba_test = final_model.predict_proba(X_test)[:, 1]\n",
    "lift_test = lift_scorer(final_model, X_test, y_test, top_pct=0.1)\n",
    "\n",
    "print(\"XGB - TEST SET\")\n",
    "print(f\"Lift@10%: {lift_test:.2f}x\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_test):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.3f}\")\n",
    "print(f\"F1: {f1_score(y_test, y_pred_test):.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cfaf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Vizualizing XGBoost curves - recall vs. lift, XGBoost vs. LR \n",
    "base_params = {\n",
    "    'colsample_bytree': 0.8, \n",
    "    'gamma': 0.1, \n",
    "    'learning_rate': 0.01, \n",
    "    'max_depth': 8,\n",
    "    'min_child_weight': 2,\n",
    "    'n_estimators': 600, \n",
    "    'subsample': 0.9,\n",
    "    'random_state': 831\n",
    "}\n",
    "\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "pos_weights = [5, 10, 23, 50, 100, 200]\n",
    "\n",
    "for thresh in thresholds:\n",
    "    recalls = []\n",
    "    lifts = []\n",
    "    \n",
    "    for pw in pos_weights:\n",
    "        xgb = XGBClassifier(**base_params, scale_pos_weight=pw)\n",
    "        xgb.fit(X_final, y_final)\n",
    "        \n",
    "        y_prob = xgb.predict_proba(X_test)[:, 1]\n",
    "        y_pred = (y_prob >= thresh).astype(int)\n",
    "        \n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        ppr = y_pred.sum() / len(y_pred)\n",
    "        lift = recall / ppr if ppr > 0 else 0\n",
    "        \n",
    "        recalls.append(recall)\n",
    "        lifts.append(lift)\n",
    "    \n",
    "    plt.plot(recalls, lifts, \n",
    "              marker='o',\n",
    "              label=f'XGB Threshold={thresh}')\n",
    "\n",
    "# Logistic Regression curve\n",
    "lr_recalls = []\n",
    "lr_lifts = []\n",
    "class_weights = [10, 25, 49, 75, 100, 150, 200, 300, 500]\n",
    "\n",
    "for cw in class_weights:\n",
    "    lr = LogisticRegression(class_weight={0: 1, 1: cw}, max_iter=1000)\n",
    "    lr.fit(X_final, y_final)\n",
    "    \n",
    "    y_prob_lr = lr.predict_proba(X_test)[:, 1]\n",
    "    y_pred_lr = (y_prob_lr >= 0.5).astype(int)\n",
    "    \n",
    "    recall_lr = recall_score(y_test, y_pred_lr)\n",
    "    ppr_lr = y_pred_lr.sum() / len(y_pred_lr)\n",
    "    lift_lr = recall_lr / ppr_lr if ppr_lr > 0 else 0\n",
    "    \n",
    "    lr_recalls.append(recall_lr)\n",
    "    lr_lifts.append(lift_lr)\n",
    "\n",
    "plt.plot(lr_recalls, lr_lifts, label='Logistic Regression', color='brown')\n",
    "\n",
    "plt.plot([0, 1], [1, 1], 'k--', label='Baseline (random)')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Lift')\n",
    "plt.title('Recall-Lift Trade-off: XGBoost vs Logistic Regression')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "#annotation for your optimal model\n",
    "plt.scatter([0.73], [6.7], s=150, color='black', marker='*', zorder=5, label='Current Model (pw=23, t=0.5)')\n",
    "plt.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "os.system('say \"Your graph is ready.\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12210c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opitmal Point automatically extraxted and W/ pos weight\n",
    "\n",
    "base_params = {\n",
    "    'colsample_bytree': 0.8, \n",
    "    'gamma': 0.1, \n",
    "    'learning_rate': 0.01, \n",
    "    'max_depth': 8,\n",
    "    'min_child_weight': 2,\n",
    "    'n_estimators': 600, \n",
    "    'subsample': 0.9,\n",
    "    'random_state': 831\n",
    "}\n",
    "\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "pos_weights = [5, 10, 23, 50, 100, 200]\n",
    "\n",
    "for thresh in thresholds:\n",
    "    recalls = []\n",
    "    lifts = []\n",
    "    for pw in pos_weights:\n",
    "        xgb = XGBClassifier(**base_params, scale_pos_weight=pw)\n",
    "        xgb.fit(X_final, y_final)\n",
    "        lift = lift_scorer(xgb, X_test, y_test, top_pct=0.1)\n",
    "        y_prob = xgb.predict_proba(X_test)[:, 1]\n",
    "        y_pred = (y_prob >= thresh).astype(int)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        recalls.append(recall)\n",
    "        lifts.append(lift)\n",
    "    \n",
    "    line, = plt.plot(recalls, lifts, marker='o', label=f'XGB Threshold={thresh}')\n",
    "    #pos_weight labels\n",
    "    for i, pw in enumerate(pos_weights):\n",
    "        plt.annotate(f'{pw}', (recalls[i], lifts[i]), fontsize=7, alpha=0.7)\n",
    "\n",
    "#Logistic Regression curve\n",
    "lr_recalls = []\n",
    "lr_lifts = []\n",
    "class_weights = [10, 25, 49, 75, 100, 150, 200, 300, 500]\n",
    "\n",
    "for cw in class_weights:\n",
    "    lr = LogisticRegression(class_weight={0: 1, 1: cw}, max_iter=1000, random_state=831)\n",
    "    lr.fit(X_final, y_final)\n",
    "    lift_lr = lift_scorer(lr, X_test, y_test, top_pct=0.1)\n",
    "    y_prob_lr = lr.predict_proba(X_test)[:, 1]\n",
    "    y_pred_lr = (y_prob_lr >= 0.5).astype(int)\n",
    "    recall_lr = recall_score(y_test, y_pred_lr)\n",
    "    lr_recalls.append(recall_lr)\n",
    "    lr_lifts.append(lift_lr)\n",
    "\n",
    "plt.plot(lr_recalls, lr_lifts, label='Logistic Regression', color='brown')\n",
    "plt.plot([0, 1], [1, 1], 'k--', label='Baseline (random)')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Lift')\n",
    "plt.title('Recall-Lift Trade-off: XGBoost vs Logistic Regression')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "#Calculate optimal model point from final_model\n",
    "y_pred_optimal = final_model.predict(X_test)\n",
    "recall_optimal = recall_score(y_test, y_pred_optimal)\n",
    "lift_optimal = lift_scorer(final_model, X_test, y_test, top_pct=0.1)\n",
    "\n",
    "plt.scatter([recall_optimal], [lift_optimal], s=150, color='black', marker='*', zorder=5, label='Current Model (pw=23, t=0.5)')\n",
    "plt.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "os.system('say \"Your graph is ready.\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b89c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and feature names\n",
    "model_package = {\n",
    "    'model': final_model,\n",
    "    'feature_names': feature_names\n",
    "}\n",
    "\n",
    "with open('xgboost_fraud_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_package, f)\n",
    "\n",
    "print(\"Model and feature names saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_ds_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
